wandb: WARNING Calling wandb.login() after wandb.init() has no effect.
Create sweep with ID: v8ldcp2x
Sweep URL: https://wandb.ai/-my/dl_assignment1/sweeps/v8ldcp2x
wandb: WARNING Calling wandb.login() after wandb.init() has no effect.
wandb: Agent Starting Run: rmtnbl0n with config:
wandb: 	batch_size: 64
wandb: 	epochs: 5
wandb: 	learning_rate: 0.001
wandb: 	n_hidden_layers: 3
wandb: 	optimizer: sgd
wandb: 	size_hidden_layers: 32
d:\IITM\deepLearning\Assignments\assignment1\main.py:253: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray
  weightsGrad += np.array(wGrad)
d:\IITM\deepLearning\Assignments\assignment1\main.py:254: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray
  biasGrad += np.array(bGrad)
d:\IITM\deepLearning\Assignments\assignment1\main.py:256: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray
  weights = weights - np.multiply(eta,weightsGrad)
d:\IITM\deepLearning\Assignments\assignment1\main.py:257: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray
  bias = bias - np.multiply(eta,biasGrad)
d:\IITM\deepLearning\Assignments\assignment1\main.py:62: RuntimeWarning: overflow encountered in exp
  out = (1/(1+np.exp(-1*parameter)))
After epoch :  1 Loss  =  [[138889.14112673]]
After epoch :  2 Loss  =  [[138627.54039283]]
After epoch :  3 Loss  =  [[138625.77307938]]
After epoch :  4 Loss  =  [[138626.05454374]]
After epoch :  5 Loss  =  [[138628.1209603]]
After epoch :  6 Loss  =  [[138633.33527948]]
After epoch :  7 Loss  =  [[138643.50846081]]
After epoch :  8 Loss  =  [[138634.66827726]]
