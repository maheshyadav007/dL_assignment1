2021-03-10 18:24:49,951 INFO    Thread-8  :13796 [wandb_setup.py:_flush():69] setting env: {'entity': '-my', 'project': 'dl_assignment1', 'root_dir': 'D:\\IITM\\deepLearning\\Assignments\\assignment1', 'sweep_id': '6x5lw3mw', 'run_id': '0o98engg', 'sweep_param_path': 'D:\\IITM\\deepLearning\\Assignments\\assignment1\\wandb\\sweep-6x5lw3mw\\config-0o98engg.yaml'}
2021-03-10 18:24:49,952 INFO    Thread-8  :13796 [wandb_setup.py:_flush():69] setting login settings: {}
2021-03-10 18:24:49,953 INFO    Thread-8  :13796 [wandb_init.py:_log_setup():319] Logging user logs to D:\IITM\deepLearning\Assignments\assignment1\wandb\run-20210310_182449-0o98engg\logs\debug.log
2021-03-10 18:24:49,954 INFO    Thread-8  :13796 [wandb_init.py:_log_setup():320] Logging internal logs to D:\IITM\deepLearning\Assignments\assignment1\wandb\run-20210310_182449-0o98engg\logs\debug-internal.log
2021-03-10 18:24:49,955 INFO    Thread-8  :13796 [wandb_init.py:init():352] calling init triggers
2021-03-10 18:24:49,955 INFO    Thread-8  :13796 [wandb_init.py:init():359] wandb.init called with sweep_config: {'alpha': 0, 'batch_size': 16, 'epochs': 10, 'hidden_Layer_AF': 'sigmoid', 'initializer': 'xavier', 'learning_rate': 0.001, 'loss_func': 'crossentropy', 'n_hidden_layers': 4, 'optimizer': 'nadam', 'size_hidden_layers': 64}
config: {}
2021-03-10 18:24:49,958 INFO    Thread-8  :13796 [wandb_init.py:init():398] wandb.init() called when a run is still active
2021-03-10 18:28:09,928 INFO    Thread-8  :13796 [wandb_run.py:finish():1078] finishing run -my/dl_assignment1/0o98engg
2021-03-10 18:28:09,932 INFO    Thread-8  :13796 [wandb_run.py:_atexit_cleanup():1392] got exitcode: 1
2021-03-10 18:28:09,932 INFO    Thread-8  :13796 [wandb_run.py:_restore():1364] restore
2021-03-10 18:28:10,495 INFO    Thread-8  :13796 [wandb_run.py:_wait_for_finish():1515] got exit ret: file_counts {
  wandb_count: 1
}
pusher_stats {
  uploaded_bytes: 787
  total_bytes: 787
}

2021-03-10 18:28:12,583 INFO    Thread-8  :13796 [wandb_run.py:_wait_for_finish():1515] got exit ret: file_counts {
  wandb_count: 4
}
pusher_stats {
  uploaded_bytes: 3708
  total_bytes: 3708
}

2021-03-10 18:28:14,617 INFO    Thread-8  :13796 [wandb_run.py:_wait_for_finish():1515] got exit ret: done: true
exit_result {
}
file_counts {
  wandb_count: 4
}
pusher_stats {
  uploaded_bytes: 3708
  total_bytes: 3708
}

2021-03-10 18:28:17,317 INFO    Thread-8  :13796 [wandb_run.py:_show_files():1737] logging synced files
2021-03-10 18:28:17,332 ERROR   MainThread:13796 [pyagent.py:_run_jobs_from_queue():231] Run 0o98engg errored: TypeError("unhashable type: 'numpy.ndarray'",)
2021-03-10 18:28:19,200 INFO    Thread-14 :13796 [wandb_setup.py:_flush():69] setting env: {'entity': '-my', 'project': 'dl_assignment1', 'root_dir': 'D:\\IITM\\deepLearning\\Assignments\\assignment1', 'sweep_id': '6x5lw3mw', 'run_id': 'ym5g7d28', 'sweep_param_path': 'D:\\IITM\\deepLearning\\Assignments\\assignment1\\wandb\\sweep-6x5lw3mw\\config-ym5g7d28.yaml'}
2021-03-10 18:28:19,201 INFO    Thread-14 :13796 [wandb_setup.py:_flush():69] setting login settings: {}
2021-03-10 18:28:19,202 INFO    Thread-14 :13796 [wandb_init.py:_log_setup():319] Logging user logs to D:\IITM\deepLearning\Assignments\assignment1\wandb\run-20210310_182819-ym5g7d28\logs\debug.log
2021-03-10 18:28:19,203 INFO    Thread-14 :13796 [wandb_init.py:_log_setup():320] Logging internal logs to D:\IITM\deepLearning\Assignments\assignment1\wandb\run-20210310_182819-ym5g7d28\logs\debug-internal.log
2021-03-10 18:28:19,204 INFO    Thread-14 :13796 [wandb_init.py:init():352] calling init triggers
2021-03-10 18:28:19,205 INFO    Thread-14 :13796 [wandb_init.py:init():359] wandb.init called with sweep_config: {'alpha': 0, 'batch_size': 16, 'epochs': 10, 'hidden_Layer_AF': 'sigmoid', 'initializer': 'xavier', 'learning_rate': 0.001, 'loss_func': 'crossentropy', 'n_hidden_layers': 4, 'optimizer': 'nadam', 'size_hidden_layers': 64}
config: {'batch_size': 64, 'learning_rate': 0.001, 'epochs': 10, 'n_hidden_layers': 4, 'size_hidden_layers': 64, 'optimizer': 'adam'}
2021-03-10 18:28:19,208 INFO    Thread-14 :13796 [wandb_init.py:init():401] starting backend
2021-03-10 18:28:19,208 INFO    Thread-14 :13796 [backend.py:_multiprocessing_setup():71] multiprocessing start_methods=spawn, using: spawn
2021-03-10 18:28:19,243 INFO    Thread-14 :13796 [backend.py:ensure_launched():123] starting backend process...
2021-03-10 18:28:19,910 INFO    Thread-14 :13796 [backend.py:ensure_launched():128] started backend process with pid: 13520
2021-03-10 18:28:19,913 INFO    Thread-14 :13796 [wandb_init.py:init():406] backend started and connected
2021-03-10 18:28:19,939 INFO    Thread-14 :13796 [wandb_run.py:_config_callback():669] config_cb None None {'alpha': 0, 'batch_size': 16, 'epochs': 10, 'hidden_Layer_AF': 'sigmoid', 'initializer': 'xavier', 'learning_rate': 0.001, 'loss_func': 'crossentropy', 'n_hidden_layers': 4, 'optimizer': 'nadam', 'size_hidden_layers': 64}
2021-03-10 18:28:19,944 INFO    Thread-14 :13796 [wandb_init.py:init():446] updated telemetry
2021-03-10 18:28:19,947 INFO    Thread-14 :13796 [wandb_init.py:init():465] communicating current version
2021-03-10 18:28:24,962 INFO    Thread-14 :13796 [wandb_init.py:init():478] communicating run to backend with 30 second timeout
2021-03-10 18:28:26,055 INFO    Thread-14 :13796 [wandb_init.py:init():503] starting run threads in backend
2021-03-10 18:28:31,087 INFO    Thread-14 :13796 [wandb_run.py:_console_start():1422] atexit reg
2021-03-10 18:28:31,094 INFO    Thread-14 :13796 [wandb_run.py:_redirect():1285] redirect: SettingsConsole.WRAP
2021-03-10 18:28:31,094 INFO    Thread-14 :13796 [wandb_run.py:_redirect():1320] Wrapping output streams.
2021-03-10 18:28:31,095 INFO    Thread-14 :13796 [wandb_run.py:_redirect():1336] Redirects installed.
2021-03-10 18:28:31,095 INFO    Thread-14 :13796 [wandb_init.py:init():527] run started, returning control to user process
2021-03-10 18:28:31,203 INFO    Thread-14 :13796 [wandb_setup.py:_flush():69] setting env: {'entity': '-my', 'project': 'dl_assignment1', 'root_dir': 'D:\\IITM\\deepLearning\\Assignments\\assignment1', 'sweep_id': '6x5lw3mw', 'run_id': 'ym5g7d28', 'sweep_param_path': 'D:\\IITM\\deepLearning\\Assignments\\assignment1\\wandb\\sweep-6x5lw3mw\\config-ym5g7d28.yaml'}
2021-03-10 18:28:31,204 INFO    Thread-14 :13796 [wandb_setup.py:_flush():69] setting login settings: {}
2021-03-10 18:28:31,206 INFO    Thread-14 :13796 [wandb_init.py:_log_setup():319] Logging user logs to D:\IITM\deepLearning\Assignments\assignment1\wandb\run-20210310_182831-ym5g7d28\logs\debug.log
2021-03-10 18:28:31,206 INFO    Thread-14 :13796 [wandb_init.py:_log_setup():320] Logging internal logs to D:\IITM\deepLearning\Assignments\assignment1\wandb\run-20210310_182831-ym5g7d28\logs\debug-internal.log
2021-03-10 18:28:31,208 INFO    Thread-14 :13796 [wandb_init.py:init():352] calling init triggers
2021-03-10 18:28:31,210 INFO    Thread-14 :13796 [wandb_init.py:init():359] wandb.init called with sweep_config: {'alpha': 0, 'batch_size': 16, 'epochs': 10, 'hidden_Layer_AF': 'sigmoid', 'initializer': 'xavier', 'learning_rate': 0.001, 'loss_func': 'crossentropy', 'n_hidden_layers': 4, 'optimizer': 'nadam', 'size_hidden_layers': 64}
config: {}
2021-03-10 18:28:31,214 INFO    Thread-14 :13796 [wandb_init.py:init():398] wandb.init() called when a run is still active
